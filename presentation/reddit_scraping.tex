\documentclass[10pt,t]{beamer}
\usetheme{Berkeley}
\usepackage{pythonhighlight}
\usepackage{graphicx}
\usecolortheme{whale}
%\usefonttheme{serif}                                             % default TeX font
\newcommand{\bi}{\begin{itemize}}                                 % begin itemize
\newcommand{\ei}{\end{itemize}}                                   % end itemize
\newcommand{\be}{\begin{enumerate}}                               % begin itemize
\newcommand{\ee}{\end{enumerate}}                                 % end itemize
\newcommand*{\ig}[2]{{\centering\includegraphics[#1]{#2}\par}}    % include graphics
\newcommand{\txt}{\texttt}										  % texttt

\setbeamercolor{normal text}{fg=black}
\setbeamercolor{title text}{fg=black}
\setbeamerfont{frametitle}{size=\large}
\setbeamercolor{section in toc}{fg=black}

\title[Engagement]{Getting Users to Engage}
\subtitle{A Look At Comments on Reddit Posts}
\author[Messier]{Christopher Messier}
% \institute[GA]{fivethirtyeight\\New York, NY}
\institute[GA]{General Assembly\\Washington, D.C.}
\date{\today}

\begin{document}
\linespread{2}

\begin{frame}
	\titlepage
\end{frame}

\begin{frame}{Overview}
	\tableofcontents
\end{frame}

\section{Reddit}
\begin{frame}{What is Reddit?}
	Reddit is a large link sharing website
	\bi 
		\item "The front page of the internet"
		\item Types of posts
			\bi
				\item Content - links, pictures, videos, articles
				\item Self Posts - text posts by the user
			\ei
		\item Users share links with communities known as subreddits
	\ei 
\end{frame}

\begin{frame}[fragile, c]{Graph of Subreddits by User Cross Posting}
	\ig{width=.75\textwidth}{subreddit_graph.png}
\end{frame}

\section{Methodology}

\begin{frame}{Measuring Engagement}
$High\;Engagement$ posts will be defined as:
	\bi
		\item Posts that have the top 10\% most comments 
		\item Binary Classification
			\bi
				\item $High\;Engagement$ = 1
				\item Everything Else = 0
			\ei
		\item Determined for each subreddit

	\ei
\end{frame}

\begin{frame}{Why Comments?}
Reddit has several intrinsic post metrics:
	\bi
		\item Upvotes/Downvotes
			\bi
				\item Count of other users choice to like or dislike a post
			\ei
		\item Rank
			\bi
				\item The page position of a post, determined by its popularity
			\ei
		\item Comments capture active engagement with the site, interaction
	\ei
\end{frame}


\begin{frame}{Data Collection}
	Data was collected during the week of 10/30/2017
	\bi 
		\item 2,923 subreddits
		\item 1,049,005 users
		\item 2,590,769 unique posts
		\item 42,374,242 comments		
	\ei 
\end{frame}


\begin{frame}{Data Collection (cont.)}
	Collected using a proprietary \texttt{python} web scraper
	\bi
		\item Attempted to get the most representative sample possible
		\item Used \texttt{r/random} to generate a random sample of subreddits
		\item Captured up to 2,000 most recent posts per subreddit
	\ei	
\end{frame}


\begin{frame}{Omitted Data}
	The following data was removed/omitted:
	\bi				
		\item Duplicate posts
		\item Posts from bots, such as AutoModerator
		\item Non-english/non-ascii posts
		\item Adult Material
	\ei	
\end{frame}

\begin{frame}{Omitted Data (cont.)}
	Analysis was performed on a subsample, $n$= 362,658:
	\bi				
		\item Computational Reasons
			\bi
				\item Limited time
				\item Limited processing power
				\item Effect on model selection
			\ei
	\ei	
\end{frame}


\begin{frame}{Natural Language Processing}
TFIDF Vectorization of the title
	\bi
		\item \underline{T}ext \underline{F}requency
		\item \underline{I}nverse \underline{D}ocument \underline{F}requency
		\item Approx. 2,538 word vectors
	\ei

Sentiment Analysis
	\bi
		\item Attempts to determine sentiment of titles from content
	\ei

\end{frame}


\section{Models}

\begin{frame}{Models}
	Modeling was performed using the \texttt{python} package \texttt{Scikit-Learn}
	
	Models used include:
	\bi
		\item Decision Trees
		\item $k$-Nearest Neighbors
		\item Random Forest
	\ei
\end{frame}

\begin{frame}{Scoring}
Models are evaluated using the following metrics:
	\bi
		\item Precision: \begin{equation}P = \frac{T_{p}}{T_{p} + F_{p}}\end{equation}
		\item Recall: \begin{equation}R = \frac{T_{p}}{T_{p} + F_{n}}\end{equation}
		\item F1:\begin{equation}F1 = \frac{2(P \times R)}{P + R}\end{equation}
	\ei
\end{frame}

\begin{frame}{Content}
Measuring the effects of the content of a post
	\bi
		\item Used a decision tree model
		\bi
			\item Minutes since posting
			\item Whether it's a question
			\item Features outside content
			\item Has an emoji in the title
		\ei
	\ei
\end{frame}

\begin{frame}[c]{Content Decision Tree Results}
Content Decision Tree Results
\begin{table}
	\begin{tabular}{l | c | c }
		& Predicted True & Predicted False\\
		\hline \hline
		True & 89122 & 9352\\ 
		False & 9352 & 972
	\end{tabular}
\end{table}
\bi
	\item Precision: 0.83
	\item Recall: 0.83
	\item F1: 0.83
\ei
\end{frame}

\begin{frame}{Sentiment}
Measuring the sentiment of a post's title, using \texttt{nltk}
	\bi
		\item Used a decision tree model
		\bi
			\item Positive
			\item Negative
			\item Neutral scores
		\ei
	\ei
\end{frame}

\begin{frame}[c]{Sentiment Decision Tree Results}
Confusion Matrix

\begin{table}
	\begin{tabular}{l | c | c }
		& Predicted True & Predicted False\\
		\hline \hline
		True & 98334 & 140\\ 
		False & 10308 & 16
	\end{tabular}
\end{table}
\bi
	\item Precision: 0.83
	\item Recall: 0.90
	\item F1: 0.86
\ei
\end{frame}

\begin{frame}{k-Nearest Neighbors}
Measuring the sentiment of the post title
	\bi
		\item Full complement of features
		\item Lazy model
			\bi
				\item Computationally Inefficient
				\item Keeps all observations in memory
			\ei
	\ei
\end{frame}

\begin{frame}[c]{k-Nearest Neighbors Results}
Confusion Matrix:

\begin{table}
	\begin{tabular}{l | c | c }
		& Predicted True & Predicted False\\
		\hline \hline
		True & 97912 & 562\\ 
		False & 9927 & 397
	\end{tabular}
\end{table}
\bi
	\item Precision: 0.86
	\item Recall: 0.90
	\item F1: 0.87
\ei
\end{frame}

\begin{frame}{Random Forest}
Measuring the sentiment of the post title
	\bi
		\item Full complement of features
		\item Computationally Brilliant
		\bi
			\item Distributable
			\item Efficient
			\item \textit{Accurate}
		\ei
	\ei
\end{frame}

\begin{frame}[c]{Random Forest Results}
Confusion Matrix:

\begin{table}
	\begin{tabular}{l | c | c }
		& Predicted True & Predicted False\\
		\hline \hline
		True & 96340 & 2134\\ 
		False & 8382 & 1942
	\end{tabular}
\end{table}
\bi
	\item Precision: 0.88
	\item Recall: 0.90
	\item F1: 0.88
\ei
\end{frame}

\section{Conclusion}
\begin{frame}
As our ability to analyze and gain understandings from data grows, it leads us to some difficult problems 
\bi
	\item Accuracy vs. Interpretablity
	\item Difficulty distilling information into general consumption
	\item The article should be aimed at highlighting this gap, and help readers understand these difficulties
\ei
\end{frame}

\begin{frame}[fragile, c]  % image frame
	\begin{center}
		\Large{Thank You}
	\end{center}
\end{frame}

\end{document}