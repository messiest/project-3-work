{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data/processed_data.csv')\n",
    "\n",
    "df = df.drop_duplicates('post_id', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225549, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=.5)  # use 10% sample for build phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1112774, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIIIIIIG Data?: True\n"
     ]
    }
   ],
   "source": [
    "data_large = True\n",
    "if df.shape[0] > 50000:\n",
    "    data_large = True\n",
    "    \n",
    "    \n",
    "print(\"BIIIIIIG Data?: {}\".format(data_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment_karma</th>\n",
       "      <th>comments</th>\n",
       "      <th>content</th>\n",
       "      <th>crossposts</th>\n",
       "      <th>karma</th>\n",
       "      <th>link</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_time</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_rank</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>title</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>outside_content</th>\n",
       "      <th>is_question</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>minutes_since_post</th>\n",
       "      <th>default_subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215057</th>\n",
       "      <td>ChEJobSearch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>/r/personalfinance/comments/79jufh/should_i_op...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/personalfinance/comments/79jufh/should_i_op...</td>\n",
       "      <td>t3_79jufh</td>\n",
       "      <td>2017-10-29 19:05:08.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>r/personalfinance</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12382010.0</td>\n",
       "      <td>Retirementshould I open up my vanguard roth ir...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1 days 13:54:11.565483000</td>\n",
       "      <td>2274.192758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              author  comment_karma  comments  \\\n",
       "215057  ChEJobSearch            NaN         6   \n",
       "\n",
       "                                                  content  crossposts  karma  \\\n",
       "215057  /r/personalfinance/comments/79jufh/should_i_op...           0    NaN   \n",
       "\n",
       "                                                     link    post_id  \\\n",
       "215057  /r/personalfinance/comments/79jufh/should_i_op...  t3_79jufh   \n",
       "\n",
       "                         post_time  score        ...          \\\n",
       "215057  2017-10-29 19:05:08.000000   18.0        ...           \n",
       "\n",
       "                subreddit subreddit_rank  subscriptions  \\\n",
       "215057  r/personalfinance           41.0     12382010.0   \n",
       "\n",
       "                                                    title has_emoji  \\\n",
       "215057  Retirementshould I open up my vanguard roth ir...         0   \n",
       "\n",
       "        outside_content  is_question               elapsed_time  \\\n",
       "215057                0            1  1 days 13:54:11.565483000   \n",
       "\n",
       "       minutes_since_post  default_subreddit  \n",
       "215057        2274.192758                  1  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['karma', 'comment_karma'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the response vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subreddit</th>\n",
       "      <th>r/100yearsago</th>\n",
       "      <th>r/1200isjerky</th>\n",
       "      <th>r/13ReasonsWhy</th>\n",
       "      <th>r/13or30</th>\n",
       "      <th>r/195</th>\n",
       "      <th>r/19KidsandCounting</th>\n",
       "      <th>r/2007scape</th>\n",
       "      <th>r/2juicy4bones</th>\n",
       "      <th>r/2meirl42meirl4meirl</th>\n",
       "      <th>r/30ROCK</th>\n",
       "      <th>...</th>\n",
       "      <th>r/xmen</th>\n",
       "      <th>r/yesyesyesno</th>\n",
       "      <th>r/yesyesyesyesno</th>\n",
       "      <th>r/yorku</th>\n",
       "      <th>r/youdontsurf</th>\n",
       "      <th>r/youseeingthisshit</th>\n",
       "      <th>r/youtube</th>\n",
       "      <th>r/youtubehaiku</th>\n",
       "      <th>r/yuruyuri</th>\n",
       "      <th>r/zen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>3.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>82.4</td>\n",
       "      <td>112.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>106.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2584 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "subreddit  r/100yearsago  r/1200isjerky  r/13ReasonsWhy  r/13or30  r/195  \\\n",
       "0.9                                                                        \n",
       "comments             3.0           14.2            23.0      32.7    2.0   \n",
       "\n",
       "subreddit  r/19KidsandCounting  r/2007scape  r/2juicy4bones  \\\n",
       "0.9                                                           \n",
       "comments                  33.2         34.0            10.2   \n",
       "\n",
       "subreddit  r/2meirl42meirl4meirl  r/30ROCK  ...    r/xmen  r/yesyesyesno  \\\n",
       "0.9                                         ...                            \n",
       "comments                    18.0      25.0  ...      23.0           26.0   \n",
       "\n",
       "subreddit  r/yesyesyesyesno  r/yorku  r/youdontsurf  r/youseeingthisshit  \\\n",
       "0.9                                                                        \n",
       "comments               31.0     11.1           82.4                112.2   \n",
       "\n",
       "subreddit  r/youtube  r/youtubehaiku  r/yuruyuri  r/zen  \n",
       "0.9                                                      \n",
       "comments        11.2            29.1        13.0  106.7  \n",
       "\n",
       "[1 rows x 2584 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_threshold = df.groupby('subreddit').quantile(.9).reset_index()[['subreddit', 'comments']].set_index('subreddit').transpose()\n",
    "\n",
    "comment_threshold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 90.5 ms, total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# response\n",
    "\n",
    "response = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    subreddit = row['subreddit']\n",
    "    comments = row['comments']\n",
    "    \n",
    "    is_greater = 0\n",
    "    if comments > comment_threshold[subreddit].values:\n",
    "        is_greater = 1\n",
    "        \n",
    "    response.append(is_greater)\n",
    "    \n",
    "\n",
    "df['response'] = response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title']\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095770, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_dummies = pd.get_dummies(df['subreddit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on the Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()\n",
    "\n",
    "sentiment = df['title'].apply(sia.polarity_scores)\n",
    "\n",
    "sent = pd.DataFrame(list(sentiment))\n",
    "\n",
    "df = df.join(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['response']\n",
    "\n",
    "\n",
    "to_drop = ['comments', 'response', 'author', 'content', 'link', 'post_id', 'subreddit', 'scrape_time', 'post_time', 'elapsed_time']\n",
    "\n",
    "x = df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.join(subreddit_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095770, 2575)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP - TFIDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english',\n",
    "                        strip_accents='unicode',\n",
    "                        max_features=df.shape[0]//10)\n",
    "\n",
    "tfidf.fit(x_train)\n",
    "\n",
    "tfidf_train = pd.DataFrame(tfidf.transform(x_train['title']).todense(), columns=tfidf.get_feature_names())\n",
    "tfidf_test = pd.DataFrame(tfidf.transform(x_test['title']).todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# x_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop('title', axis=1)\n",
    "x_test = x_test.drop('title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.join(tfidf_train, lsuffix='_df')\n",
    "x_test = x_test.join(tfidf_test, lsuffix='_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.fillna(0.0, inplace=True)\n",
    "x_test.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "forest = RandomForestClassifier(n_jobs=-1)\n",
    "if not data_large:\n",
    "    boost = GradientBoostingClassifier()\n",
    "bag = BaggingClassifier(n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 11s, sys: 1h 28min 46s, total: 1h 57min 57s\n",
      "Wall time: 43min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "forest.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if not data_large:\n",
    "    boost.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bag.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "knn.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "forest_predictions = forest.predict(x_test)\n",
    "if not data_large: boost_predictions = boost.predict(x_test)\n",
    "bag_predictions = bag.predict(x_test)\n",
    "knn_predictions = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest:\\n\", classification_report(y_test, forest_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_large: print(\"Gradient Boost:\\n\", classification_report(y_test, boost_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bagging:\\n\", classification_report(y_test, bag_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"kNN:\\n\", classification_report(y_test, knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
